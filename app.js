// ==========================================
// 1. DOM ìš”ì†Œ ê°€ì ¸ì˜¤ê¸°
// ==========================================
const landingPage = document.getElementById("landing-page");
const cameraPage = document.getElementById("camera-page");
const resultPage = document.getElementById("result-page");

const video = document.getElementById("video");
const canvas = document.getElementById("outputCanvas");
const scannedImage = document.getElementById("scannedImage");
const guideBox = document.querySelector(".camera-guide-box");

const startCaptureBtn = document.getElementById("startCaptureBtn");
const shutterBtn = document.getElementById("shutterBtn");
const closeCameraBtn = document.getElementById("closeCameraBtn");
const retakeBtn = document.getElementById("retakeBtn");
const saveBtn = document.getElementById("saveBtn");

// ìƒíƒœ ì œì–´ ë³€ìˆ˜
let stream = null;
let detectReq = null;
let isCapturing = false;
let stableCount = 0;
let lastGoodCoords = null; // ê°€ì¥ ìµœê·¼ì— ì°¾ì€ ë§ˆì»¤ ì¢Œí‘œ

// ==========================================
// 2. ì¹´ë©”ë¼ ì œì–´
// ==========================================
async function startCamera() {
  if (!window.isOpenCvReady) {
    alert("ì—”ì§„ ë¡œë“œ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”.");
    return;
  }

  try {
    landingPage.style.display = "none";
    resultPage.style.display = "none";
    cameraPage.style.display = "flex";

    const constraints = {
      video: {
        facingMode: "environment",
        width: { ideal: 3840 },
        height: { ideal: 2160 },
      },
      audio: false,
    };

    stream = await navigator.mediaDevices.getUserMedia(constraints);
    video.srcObject = stream;
    video.setAttribute("playsinline", true);
    video.play();

    // ë¹„ë””ì˜¤ ì¬ìƒì´ ì‹œì‘ë˜ë©´ ì‹¤ì‹œê°„ ë§ˆì»¤ íƒìƒ‰ ë£¨í”„ ì‹¤í–‰
    isCapturing = false;
    stableCount = 0;
    detectReq = requestAnimationFrame(scanMarkersLoop);
  } catch (err) {
    alert("ì¹´ë©”ë¼ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.");
    closeCamera();
  }
}

function closeCamera() {
  if (detectReq) cancelAnimationFrame(detectReq);
  isCapturing = true;

  if (stream) {
    stream.getTracks().forEach((track) => track.stop());
    stream = null;
  }
  video.srcObject = null;
  cameraPage.style.display = "none";
  landingPage.style.display = "block";
  guideBox.classList.remove("detected");
}

// ==========================================
// 3. ì‹¤ì‹œê°„ ë§ˆì»¤ íƒìƒ‰ ë£¨í”„ (ì´ˆê³ ì† ì €í•´ìƒë„ ì²˜ë¦¬)
// ==========================================
function scanMarkersLoop() {
  if (!stream || isCapturing) return;

  const vW = video.videoWidth;
  const vH = video.videoHeight;

  if (vW === 0) {
    detectReq = requestAnimationFrame(scanMarkersLoop);
    return;
  }

  // ğŸ”§ [íŠœë‹ 1] íƒìƒ‰ í•´ìƒë„ ìƒí–¥ (640 -> 800)
  // í™”ë©´ì„ ë„ˆë¬´ ë§ì´ ì¤„ì´ë©´ ì‘ì€ ë§ˆì»¤ê°€ ë­‰ê°œì§€ë¯€ë¡œ í•´ìƒë„ë¥¼ ì¡°ê¸ˆ ë†’ì˜€ìŠµë‹ˆë‹¤.
  const scale = 800 / Math.max(vW, vH);
  const dW = Math.floor(vW * scale);
  const dH = Math.floor(vH * scale);

  if (!window.detectCanvas)
    window.detectCanvas = document.createElement("canvas");
  window.detectCanvas.width = dW;
  window.detectCanvas.height = dH;

  const ctx = window.detectCanvas.getContext("2d", {
    willReadFrequently: true,
  });
  ctx.drawImage(video, 0, 0, dW, dH);

  let src = cv.imread(window.detectCanvas);
  let gray = new cv.Mat();
  let thresh = new cv.Mat();
  let contours = new cv.MatVector();
  let hierarchy = new cv.Mat();

  try {
    cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);

    // ğŸ”§ [íŠœë‹ 2] ê°€ë²¼ìš´ ë¸”ëŸ¬ ì²˜ë¦¬ ì¶”ê°€ (ë¹› ë°˜ì‚¬ ë° ë…¸ì´ì¦ˆ ì œê±°ìš©)
    cv.GaussianBlur(gray, gray, new cv.Size(3, 3), 0, 0, cv.BORDER_DEFAULT);

    // ì´ì§„í™” ì²˜ë¦¬
    cv.adaptiveThreshold(
      gray,
      thresh,
      255,
      cv.ADAPTIVE_THRESH_MEAN_C,
      cv.THRESH_BINARY_INV,
      51,
      10
    );

    // ğŸ”§ [íŠœë‹ 3] íƒìƒ‰ ëª¨ë“œ ë³€ê²½ (RETR_EXTERNAL -> RETR_LIST)
    // ìš©ì§€ ì™¸ê³½ì„  ì•ˆìª½ì— ë§ˆì»¤ê°€ ìˆë‹¤ê³  íŒë‹¨í•´ ë¬´ì‹œí•˜ëŠ” í˜„ìƒ ë°©ì§€
    cv.findContours(
      thresh,
      contours,
      hierarchy,
      cv.RETR_LIST,
      cv.CHAIN_APPROX_SIMPLE
    );

    let candidates = [];

    // ğŸ”§ [íŠœë‹ 4] ë§ˆì»¤ ìµœì†Œ í¬ê¸° ì¡°ê±´ ëŒ€í­ ì™„í™” (0.0005 -> 0.0001)
    // ì ì´ í™”ë©´ì—ì„œ ì°¨ì§€í•˜ëŠ” ë¹„ìœ¨ì´ ì•„ì£¼ ì‘ì•„ë„ í›„ë³´ì— ë„£ìŠµë‹ˆë‹¤.
    const minArea = dW * dH * 0.0001;
    const maxArea = dW * dH * 0.05;

    for (let i = 0; i < contours.size(); ++i) {
      let cnt = contours.get(i);
      let area = cv.contourArea(cnt);

      if (area > minArea && area < maxArea) {
        let rect = cv.boundingRect(cnt);
        let aspect = rect.width / rect.height;
        let extent = area / (rect.width * rect.height);

        // ğŸ”§ [íŠœë‹ 5] í˜•íƒœ í—ˆìš©ì¹˜ ì™„í™”
        // ê°€ë¡œì„¸ë¡œ ë¹„ìœ¨(0.5~2.0)ì„ ëŠ˜ë ¤ ì‚´ì§ ì°Œê·¸ëŸ¬ì ¸ë„ í†µê³¼ì‹œí‚¤ê³ ,
        // ì†ì´ ê½‰ ì°¬ ì •ë„(extent)ë¥¼ 0.5 -> 0.4ë¡œ ë‚®ì¶°ì„œ ë¹› ë°˜ì‚¬ë¡œ ì  ì•ˆì´ ì‚´ì§ í•˜ì–—ê²Œ ë¹„ì–´ë„ í†µê³¼ì‹œí‚µë‹ˆë‹¤.
        if (aspect >= 0.5 && aspect <= 2.0 && extent >= 0.4) {
          candidates.push({
            x: rect.x + rect.width / 2,
            y: rect.y + rect.height / 2,
          });
        }
      }
    }

    if (candidates.length >= 4) {
      candidates.sort((a, b) => a.x + a.y - (b.x + b.y));
      let tl = candidates[0];
      let br = candidates[candidates.length - 1];

      candidates.sort((a, b) => a.x - a.y - (b.x - b.y));
      let bl = candidates[0];
      let tr = candidates[candidates.length - 1];

      // ê°€ì¥ ë°”ê¹¥ìª½ì˜ ì  4ê°œê°€ ì´ë£¨ëŠ” ê°€ë¡œ ê¸¸ì´ê°€ ì „ì²´ í™”ë©´ì˜ 30% ì´ìƒì¼ ë•Œë§Œ ìš©ì§€ë¡œ ì¸ì‹ (ë…¸ì´ì¦ˆ ë°©ì§€)
      if (tr.x - tl.x > dW * 0.3) {
        stableCount++;
        guideBox.classList.add("detected");

        lastGoodCoords = {
          tl: { x: tl.x / scale, y: tl.y / scale },
          tr: { x: tr.x / scale, y: tr.y / scale },
          br: { x: br.x / scale, y: br.y / scale },
          bl: { x: bl.x / scale, y: bl.y / scale },
        };

        if (stableCount > 10) {
          isCapturing = true;
          executeHighResCapture(lastGoodCoords);
          return;
        }
      } else {
        resetDetection();
      }
    } else {
      resetDetection();
    }
  } catch (err) {
    console.error("íƒìƒ‰ ì—ëŸ¬:", err);
  } finally {
    src.delete();
    gray.delete();
    thresh.delete();
    contours.delete();
    hierarchy.delete();
  }

  if (!isCapturing) detectReq = requestAnimationFrame(scanMarkersLoop);
}

function resetDetection() {
  stableCount = 0;
  lastGoodCoords = null;
  guideBox.classList.remove("detected");
}

// ==========================================
// 4. ê³ í•´ìƒë„ ì´ë¯¸ì§€ ì²˜ë¦¬ (ë§ˆì»¤ ê¸°ë°˜)
// ==========================================
function executeHighResCapture(coords) {
  guideBox.classList.remove("detected");

  const vW = video.videoWidth;
  const vH = video.videoHeight;
  canvas.width = vW;
  canvas.height = vH;

  const ctx = canvas.getContext("2d", { willReadFrequently: true });
  ctx.drawImage(video, 0, 0, vW, vH);

  let src = cv.imread(canvas);
  let dst = new cv.Mat();
  let dsize = new cv.Size(1728, 2200);

  try {
    let srcTri = cv.matFromArray(4, 1, cv.CV_32FC2, [
      coords.tl.x,
      coords.tl.y,
      coords.tr.x,
      coords.tr.y,
      coords.br.x,
      coords.br.y,
      coords.bl.x,
      coords.bl.y,
    ]);
    let dstTri = cv.matFromArray(4, 1, cv.CV_32FC2, [
      0,
      0,
      dsize.width,
      0,
      dsize.width,
      dsize.height,
      0,
      dsize.height,
    ]);

    let M = cv.getPerspectiveTransform(srcTri, dstTri);
    cv.warpPerspective(
      src,
      dst,
      M,
      dsize,
      cv.INTER_LINEAR,
      cv.BORDER_CONSTANT,
      new cv.Scalar()
    );

    cv.cvtColor(dst, dst, cv.COLOR_RGBA2GRAY, 0);
    cv.adaptiveThreshold(
      dst,
      dst,
      255,
      cv.ADAPTIVE_THRESH_GAUSSIAN_C,
      cv.THRESH_BINARY,
      21,
      15
    );

    cv.imshow(canvas, dst);
    scannedImage.src = canvas.toDataURL("image/jpeg", 0.9);

    // í™”ë©´ ì „í™˜
    if (stream) {
      stream.getTracks().forEach((track) => track.stop());
      stream = null;
    }
    cameraPage.style.display = "none";
    resultPage.style.display = "flex";

    srcTri.delete();
    dstTri.delete();
    M.delete();
  } catch (err) {
    alert("ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.");
  } finally {
    src.delete();
    dst.delete();
  }
}

// ==========================================
// 5. ìˆ˜ë™ ì´¬ì˜ (ìˆ˜ë™ ë²„íŠ¼ í´ë¦­ ì‹œ / ë§ˆì»¤ ëª» ì°¾ì•˜ì„ ë•Œ ëŒ€ë¹„ìš©)
// ==========================================
function manualFallbackCapture() {
  if (isCapturing) return;
  isCapturing = true; // ë£¨í”„ ì •ì§€

  // ë§Œì•½ ì´ˆë¡ë¶ˆì´ ëœ¬ ìƒíƒœì—ì„œ ì„±ê¸‰í•˜ê²Œ ë²„íŠ¼ì„ ëˆŒë €ë‹¤ë©´ ìë™ ì´¬ì˜ ë¡œì§ ê°•ì œ ì‹¤í–‰
  if (lastGoodCoords) {
    executeHighResCapture(lastGoodCoords);
    return;
  }

  // ë§ˆì»¤ë¥¼ ì•„ì˜ˆ ëª» ì°¾ì•˜ëŠ”ë° ë²„íŠ¼ì„ ëˆ„ë¥¸ ê²½ìš° -> í™”ë©´ ì¤‘ì•™ ê°€ì´ë“œ ë°•ìŠ¤ ì˜ì—­ë§Œ ì˜ë¼ëƒ„
  const vW = video.videoWidth;
  const vH = video.videoHeight;
  canvas.width = vW;
  canvas.height = vH;
  const ctx = canvas.getContext("2d");
  ctx.drawImage(video, 0, 0, vW, vH);

  // CSS object-fit: cover ì—­ê³„ì‚°
  const videoRatio = vW / vH;
  const screenRatio = video.clientWidth / video.clientHeight;
  const guideRect = guideBox.getBoundingClientRect();
  const videoRect = video.getBoundingClientRect();

  let scale,
    offsetX = 0,
    offsetY = 0;
  if (screenRatio > videoRatio) {
    scale = vW / video.clientWidth;
    offsetY = (vH - video.clientHeight * scale) / 2;
  } else {
    scale = vH / video.clientHeight;
    offsetX = (vW - video.clientWidth * scale) / 2;
  }

  let rx = (guideRect.left - videoRect.left) * scale + offsetX;
  let ry = (guideRect.top - videoRect.top) * scale + offsetY;
  let rw = guideRect.width * scale;
  let rh = guideRect.height * scale;

  let src = cv.imread(canvas);
  let dst = new cv.Mat();
  let dsize = new cv.Size(1728, 2200);

  try {
    // í™”ë©´ì— ë³´ì´ëŠ” ì¤‘ì•™ ë°•ìŠ¤ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í´ê¸°
    let srcTri = cv.matFromArray(4, 1, cv.CV_32FC2, [
      rx,
      ry,
      rx + rw,
      ry,
      rx + rw,
      ry + rh,
      rx,
      ry + rh,
    ]);
    let dstTri = cv.matFromArray(4, 1, cv.CV_32FC2, [
      0,
      0,
      dsize.width,
      0,
      dsize.width,
      dsize.height,
      0,
      dsize.height,
    ]);
    let M = cv.getPerspectiveTransform(srcTri, dstTri);
    cv.warpPerspective(
      src,
      dst,
      M,
      dsize,
      cv.INTER_LINEAR,
      cv.BORDER_CONSTANT,
      new cv.Scalar()
    );

    cv.cvtColor(dst, dst, cv.COLOR_RGBA2GRAY, 0);
    cv.adaptiveThreshold(
      dst,
      dst,
      255,
      cv.ADAPTIVE_THRESH_GAUSSIAN_C,
      cv.THRESH_BINARY,
      21,
      15
    );

    cv.imshow(canvas, dst);
    scannedImage.src = canvas.toDataURL("image/jpeg", 0.9);

    if (stream) {
      stream.getTracks().forEach((track) => track.stop());
      stream = null;
    }
    cameraPage.style.display = "none";
    resultPage.style.display = "flex";

    srcTri.delete();
    dstTri.delete();
    M.delete();
  } catch (e) {
    alert("ìº¡ì²˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.");
  } finally {
    src.delete();
    dst.delete();
  }
}

// ==========================================
// 6. ê²°ê³¼ í™”ë©´ ë™ì‘
// ==========================================
function retakePhoto() {
  resultPage.style.display = "none";
  startCamera();
}

function saveImage() {
  try {
    const ctx = canvas.getContext("2d");
    const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
    const tiffUint8Array = UTIF.encodeImage(
      imageData.data,
      canvas.width,
      canvas.height
    );
    const blob = new Blob([tiffUint8Array], { type: "image/tiff" });

    const url = URL.createObjectURL(blob);
    const link = document.createElement("a");
    const timestamp = new Date()
      .toISOString()
      .replace(/[-:T.]/g, "")
      .slice(0, 14);
    link.download = `scan_${timestamp}.tif`;
    link.href = url;

    document.body.appendChild(link);
    link.click();
    document.body.removeChild(link);
    URL.revokeObjectURL(url);
  } catch (err) {
    alert("íŒŒì¼ ë‹¤ìš´ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.");
  }
}

// ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ ì—°ê²°
if (startCaptureBtn) startCaptureBtn.addEventListener("click", startCamera);
if (closeCameraBtn) closeCameraBtn.addEventListener("click", closeCamera);
if (shutterBtn) shutterBtn.addEventListener("click", manualFallbackCapture);
if (retakeBtn) retakeBtn.addEventListener("click", retakePhoto);
if (saveBtn) saveBtn.addEventListener("click", saveImage);
